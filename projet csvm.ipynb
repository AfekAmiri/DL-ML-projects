{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKVXotfqrUZ2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount ('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EARp0m_TPGt9"
      },
      "source": [
        "1.   Imports utiles\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EnrHQMMrVsY"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg19 import VGG19,preprocess_input\n",
        "from sklearn.feature_selection import SelectPercentile\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from albumentations import MotionBlur\n",
        "from sklearn.preprocessing import StandardScaler \n",
        "import os\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "import seaborn as sns; sns.set()\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD9njkdHPYle"
      },
      "source": [
        "2.   Importer le modèle pré-entrainé\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sExzMYbtrZgD"
      },
      "outputs": [],
      "source": [
        "vgg19=VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDd4OjsePmfK"
      },
      "source": [
        "3.   Le chemin d'accès à la base de données\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c6-tp2Q3PUb"
      },
      "outputs": [],
      "source": [
        "train_path=\"/content/drive/MyDrive/tomato_train\"\n",
        "test_path=\"/content/drive/MyDrive/tomato_test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFu-sjzfP3Fi"
      },
      "source": [
        "4.   Extraction des variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU5BjyI1mVHb"
      },
      "outputs": [],
      "source": [
        "def blur_fct(img):\n",
        " transform=MotionBlur(p=0.2)\n",
        " return(transform(image=img)['image'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42pE9pK3pwpj"
      },
      "outputs": [],
      "source": [
        "#file generator\n",
        "class FG : \n",
        "  train_dir = os.path.join(train_path)\n",
        "  test_dir = os.path.join(test_path)\n",
        "  datagenerator = ImageDataGenerator(preprocessing_function=blur_fct,rotation_range=90)\n",
        "  batch_size = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5f8-o7TsuC-"
      },
      "outputs": [],
      "source": [
        "target_size=(224,224)\n",
        "def feature_extractor(path, nb_images,base_model):\n",
        "    features = np.empty(shape=(nb_images,base_model.output_shape[1],\n",
        "                               base_model.output_shape[2],base_model.output_shape[3]))\n",
        "    labels = np.empty(shape=(nb_images, 10))\n",
        "    generator =FG.datagenerator.flow_from_directory(path,target_size=target_size,\n",
        "                                    batch_size=FG.batch_size,class_mode='categorical')\n",
        "    i = 0\n",
        "    for inputs_batch, labels_batch in tqdm(generator):\n",
        "      preprocessed_batch=preprocess_input(inputs_batch)\n",
        "    #will convert the input images from RGB to BGR, \n",
        "    #then will zero-center each color channel with respect to the ImageNet dataset, \n",
        "    #without scaling.\n",
        "      features_batch = base_model.predict(preprocessed_batch)\n",
        "      features[i * FG.batch_size : (i + 1) * FG.batch_size] = features_batch\n",
        "      labels[i * FG.batch_size : (i + 1) * FG.batch_size] = labels_batch\n",
        "      i += 1\n",
        "      if i * FG.batch_size==nb_images:\n",
        "          break\n",
        "    return features,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjrdPtgeuLZX"
      },
      "outputs": [],
      "source": [
        "train_features,train_labels= feature_extractor(FG.train_dir,10000,vgg19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngSBSkU_VEIL"
      },
      "outputs": [],
      "source": [
        "test_features,test_labels=feature_extractor(FG.test_dir,1000,vgg19)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67GaqLybQEDH"
      },
      "source": [
        "5.   Les noms de classes \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCqtjXdpGk91"
      },
      "outputs": [],
      "source": [
        "generator = FG.datagenerator.flow_from_directory(train_path,target_size=(224,224),\n",
        "                                        batch_size=20,class_mode='categorical')\n",
        "class_indices=generator.class_indices\n",
        "class_names={class_indices[i]:i for i in class_indices.keys()}\n",
        "class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp5spNrJQO7_"
      },
      "source": [
        "6.   Manipulations des nouvelles bases de données à l'aide de Pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Stockage des données dans des fichiers csv"
      ],
      "metadata": {
        "id": "U9UW_at2XG-3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAK-1Q-Q3ZCH"
      },
      "outputs": [],
      "source": [
        "n_variables=vgg19.output_shape[1]*vgg19.output_shape[2]*vgg19.output_shape[3]\n",
        "train_features=np.reshape(train_features,(10000,n_variables))\n",
        "df1=pd.DataFrame(train_features, columns = ['feature {}'.format(i) for i in range(n_variables)])\n",
        "df1.to_csv('train features')\n",
        "df2=pd.DataFrame(train_labels)\n",
        "df2.to_csv('train labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZdZRSp6lmXt"
      },
      "outputs": [],
      "source": [
        "test_features=np.reshape(test_features,(1000,n_variables))\n",
        "df3=pd.DataFrame(test_features,columns = ['feature {}'.format(i) for i in range(n_variables)])\n",
        "df3.to_csv('test features')\n",
        "df4=pd.DataFrame(test_labels)\n",
        "df4.to_csv('test labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_Azh2BNPlK5Y",
        "outputId": "22d76dd2-8f0f-4fb3-aba7-2de092bddcd9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_d257d754-d19d-4672-a052-9b33a85457f3\", \"train features\", 1468048463)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('train features')\n",
        "files.download('train labels')\n",
        "files.download('test features')\n",
        "files.download('test labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuhcB7m_hAG_"
      },
      "source": [
        "b) Une fois les données stockées, une simple lecture me permet de les charger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-ggE6JIbYC5"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv('/content/drive/MyDrive/train features',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht6bqOS6gibb"
      },
      "outputs": [],
      "source": [
        "df3=pd.read_csv('/content/drive/MyDrive/test features',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d71MGWbqgZgV"
      },
      "outputs": [],
      "source": [
        "df2=pd.read_csv('/content/drive/MyDrive/train labels',index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LW37BE5ygqSW"
      },
      "outputs": [],
      "source": [
        "df4=pd.read_csv('/content/drive/MyDrive/test labels',index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBrWi_GvQl_g"
      },
      "source": [
        "7.   Encoder les étiquettes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpJGtdIvz1O5"
      },
      "outputs": [],
      "source": [
        "def label_encoder (Y) : \n",
        "  encoded_labels = np.array([list(Y.T[i]).index(1) for i in range (Y.shape[0])])\n",
        "  return encoded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woGy2Yma-Kyt"
      },
      "outputs": [],
      "source": [
        "y_train=label_encoder(df2)\n",
        "y_test=label_encoder(df4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrgtoRkqQvPy"
      },
      "source": [
        " 8.   Sélection des variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Test d'homogéniété"
      ],
      "metadata": {
        "id": "4GnkBt_onKXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test=stats.normaltest(df1, axis=0, nan_policy='propagate')\n",
        "score,p_value=test\n",
        "result=[x<=0.05 for x in p_value]\n",
        "# l'hypothèse de normalité peut être rejetée si p_value<=0.05\n",
        "result.count(True)\n",
        "# les échantillons ne suivent pas une loi normale ! \n",
        "#Pour cela j'ai opté pour une version non paramétrique du test ANOVA."
      ],
      "metadata": {
        "id": "PHegflFo9a1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# j'ai adapté le test kruskal pour l'utiliser avec SelectPercentile de Sklearn\n",
        "def kruskal(X,y):\n",
        " X=pd.DataFrame(X)\n",
        " KruskalResult=[[],[]]\n",
        " i=0\n",
        " for c in X.columns:\n",
        "   k=[[X[c][i] for i in range(10000) if y[i]==0],\n",
        "     [X[c][i] for i in range(10000) if y[i]==1],\n",
        "     [X[c][i] for i in range(10000) if y[i]==2],\n",
        "      [X[c][i] for i in range(10000) if y[i]==3],\n",
        "      [X[c][i] for i in range(10000) if y[i]==4],\n",
        "     [X[c][i] for i in range(10000) if y[i]==5],\n",
        "     [X[c][i] for i in range(10000) if y[i]==6],\n",
        "     [X[c][i] for i in range(10000) if y[i]==7],\n",
        "     [X[c][i] for i in range(10000) if y[i]==8],\n",
        "     [X[c][i] for i in range(10000) if y[i]==9]]\n",
        "   if k[0]==k[1]==k[2]==k[3]==k[4]==k[5]==k[6]==k[7]==k[8]==k[9]:\n",
        "       KruskalResult[0].append(None)\n",
        "       KruskalResult[0].append(None)\n",
        "   else:\n",
        "    KruskalResult[0].append(stats.kruskal(k[0],k[1],k[2],k[3],k[4],k[5],\n",
        "                                          k[6],k[7],k[8],k[9])[0])\n",
        "    KruskalResult[1].append(stats.kruskal(k[0],k[1],k[2],k[3],k[4],k[5],\n",
        "                                          k[6],k[7],k[8],k[9])[1])\n",
        " return(KruskalResult)"
      ],
      "metadata": {
        "id": "-uz2Y5yxnBu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Choisir le pourcentage de variables à garder"
      ],
      "metadata": {
        "id": "z_km7RpXYTUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReRZa8ravmuH"
      },
      "outputs": [],
      "source": [
        "# la standardisation est une étape primordiale\n",
        "scaler=StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QZvCUzZLXaj"
      },
      "outputs": [],
      "source": [
        "def best_percentile_kernel(kernel):\n",
        "  L=[]\n",
        "  for p in tqdm([100,90,80,90,70,60,50,40,30,20,10,1]):\n",
        "     selecteur=SelectPercentile(kruskal,percentile=p)\n",
        "     selecteur.fit(df1,y_train)\n",
        "     x_train=df1.T[selecteur.get_support()].T\n",
        "     x_train=scaler.fit_transform(x_train)\n",
        "     if kernel=='poly':\n",
        "      model=SVC(decision_function_shape='ovo',kernel=kernel,gamma='scale',\n",
        "                degree=2,C=1)\n",
        "     elif kernel=='rbf':\n",
        "      model=SVC(decision_function_shape='ovo',kernel=kernel,gamma='scale',C=1)\n",
        "     else:\n",
        "       model=SVC(decision_function_shape='ovo',kernel=kernel,C=1)\n",
        "     L.append(cross_val_score(model,x_train, y_train, \n",
        "                              cv=10,verbose=10).mean()*100)\n",
        "  return(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyHi2j4oUViq"
      },
      "outputs": [],
      "source": [
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_kernel('linear'),\n",
        "         label='noyau linéaire et c=1')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_kernel('rbf'),\n",
        "         label='noyau RBF, gamma=\"scale\" et c=1')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_kernel('poly'),\n",
        "         label='noyau polynomial, gamma=\"scale\", degré=2 et c=1')\n",
        "plt.xlabel('percentile')\n",
        "plt.ylabel('score (%)')\n",
        "plt.title('Evolution du score en fonction du percentile')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RMeMZxkSi2A"
      },
      "outputs": [],
      "source": [
        "def best_percentile_C(c):\n",
        "  L=[]\n",
        "  for p in tqdm([100,90,80,70,60,50,40,30,20,10,1]):\n",
        "     selecteur=SelectPercentile(kruskal,percentile=p)\n",
        "     selecteur.fit(df1,y_train)\n",
        "     x_train=df1.T[selecteur.get_support()].T\n",
        "     model=SVC(decision_function_shape='ovo',kernel='poly',gamma='scale',coef0=1,\n",
        "               degree=2,C=c)\n",
        "     L.append(cross_val_score(model,x_train, y_train, cv=10,\n",
        "                              verbose=10).mean()*100))\n",
        "  return(L)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_C(1),\n",
        "         label='C=1')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_C(10),\n",
        "         label='C=10')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_C(100),\n",
        "         label='C=100')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_C(1000),\n",
        "         label='C=1000')\n",
        "plt.xlabel('percentile')\n",
        "plt.ylabel('score (%)')\n",
        "plt.title('Evolution du score en fonction du percentile gamma=\"scale\",degré=2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FdHMNXRI5Rlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_percentile_gamma(gamma):\n",
        "  L=[]\n",
        "  for p in tqdm([100,90,80,70,60,50,40,30,20,10,1]):\n",
        "     selecteur=SelectPercentile(kruskal,percentile=p)\n",
        "     selecteur.fit(df1,y_train)\n",
        "     x_train=df1.T[selecteur.get_support()].T\n",
        "     x_train=scaler.fit_transform(x_train)\n",
        "     model=SVC(decision_function_shape='ovo',kernel='poly',gamma=gamma,coef0=1,\n",
        "               degree=2,C=1)\n",
        "     L.append(cross_val_score(model,x_train, y_train, cv=10,\n",
        "                              verbose=10).mean()*100)\n",
        "  return(L)  "
      ],
      "metadata": {
        "id": "zGHD4hI-Kg76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_gamma('scale'),\n",
        "         label=\"Gamma='scale'\")\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_gamma('auto'),\n",
        "         label=\"Gamma='auto'\")\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_gamma(1e-4),\n",
        "         label='Gamma=1e-4')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_gamma(1e-2),\n",
        "         label='Gamma=1e-2')\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_gamma(0.1),\n",
        "         label='Gamma=0.1')\n",
        "plt.xlabel('percentile')\n",
        "plt.ylabel('score (%)')\n",
        "plt.title('Evolution du score en fonction du percentile C=1, coef0=1 et degré=2')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UHiVyxx253tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_percentile_degree(degree):\n",
        "  L=[]\n",
        "  for p in tqdm([100,90,80,70,60,50,40,30,20,10,1]):\n",
        "     selecteur=SelectPercentile(kruskal,percentile=p)\n",
        "     selecteur.fit(df1,y_train)\n",
        "     x_train=df1.T[selecteur.get_support()].T\n",
        "     x_train=scaler.fit_transform(x_train)\n",
        "     model=SVC(decision_function_shape='ovo',kernel='poly',gamma='scale',coef0=0,\n",
        "               degree=degree,C=1)\n",
        "     model.fit(x_train,y_train)\n",
        "     L.append(cross_val_score(model,x_train, y_train, \n",
        "                              cv=10,verbose=10).mean()*100)\n",
        "  return(L)"
      ],
      "metadata": {
        "id": "MvgzSBux3RWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_degree(2),\n",
        "         label=\"degré=2\")\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_degree(3),\n",
        "         label=\"degré=3\")\n",
        "plt.plot([100,90,80,70,60,50,40,30,20,10,1],best_percentile_degree(4),\n",
        "         label=\"degré=4\")\n",
        "plt.xlabel('percentile')\n",
        "plt.ylabel('score (%)')\n",
        "plt.title(\"Evolution du score en fonction du percentile gamma='scale' et C=1\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "29X9Yk-R6nVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzy_2fRxFwCn"
      },
      "source": [
        "10. Ajuster les paramètres du modèle\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) Noyau linéaire"
      ],
      "metadata": {
        "id": "Edi1_gzCeixP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyjwkNSN_iv_"
      },
      "outputs": [],
      "source": [
        "selecteur=SelectPercentile(kruskal,percentile=80)\n",
        "selecteur.fit(df1,y_train)\n",
        "x_train=df1.T[selecteur.get_support()].T\n",
        "x_train=scaler.fit_transform(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8p4v2AxP6kFE"
      },
      "outputs": [],
      "source": [
        "parameters = {'C':[1e-5,1e-4,0.001,0.01,0.1,1,10,100,1000]}\n",
        "clf = GridSearchCV(SVC(decision_function_shape='ovo',kernel='linear'),parameters,\n",
        "                   verbose=10)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.best_params_\n",
        "clf.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) Noyau RBF"
      ],
      "metadata": {
        "id": "ShyZZ8FlmvNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selecteur=SelectPercentile(kruskal,percentile=60)\n",
        "selecteur.fit(df1,y_train)\n",
        "x_train=df1.T[selecteur.get_support()].T\n",
        "x_train=scaler.fit_transform(x_train)"
      ],
      "metadata": {
        "id": "l2B1_ktUm9E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_w_4zImND9dm"
      },
      "outputs": [],
      "source": [
        "parameters = {'C':[0.1,1,10,100,1000],'gamma':[1e-7,1e-6,'auto','scale']}\n",
        "clf = GridSearchCV(SVC(decision_function_shape='ovo',kernel='rbf'),parameters,\n",
        "                   cv=10,verbose=10)\n",
        "clf.fit(x_train,y_train)\n",
        "clf.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kRjvVyFGDgV"
      },
      "source": [
        "12.   Évaluation des performances du meilleur modèle\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selecteur=SelectPercentile(kruskal,percentile=60)\n",
        "selecteur.fit(df1,y_train)\n",
        "x_train=df1.T[selecteur.get_support()].T\n",
        "x_train=scaler.fit_transform(x_train)\n",
        "x_test=df3.T[selecteur.get_support()].T\n",
        "x_test=scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "jYp8PGLQvqRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=SVC(decision_function_shape='ovo',kernel='rbf',C=100,gamma=1e-6)\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "PUXeFFbanuby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VX2X3SSyi4v_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_fit=model.predict(x_test)\n",
        "print(classification_report(y_test, y_fit))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_hZ9sNGXLie"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "mat = confusion_matrix(y_test, y_fit)\n",
        "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
        "            xticklabels=class_names.keys(),yticklabels=class_names.keys())\n",
        "plt.xlabel('true label')\n",
        "plt.ylabel('predicted label');"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Enregistrer le modèle"
      ],
      "metadata": {
        "id": "oBwSymJMAexj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# enregistrer le modèle\n",
        "import pickle \n",
        "fichier='modèle_RBF_Gamma=1e-6_C=100.sav'\n",
        "pickle.dump(model,open(fichier,'wb'))"
      ],
      "metadata": {
        "id": "-oL4kwaa_N-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('modèle_RBF_Gamma=1e-6_C=100.sav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ymyFHkgwBaVF",
        "outputId": "c3379b71-bd53-4355-a9ee-9f24ba7cab0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cf12dad2-6413-4b27-8f80-e9584ea87eaa\", \"mod\\u00e8le_RBF_Gamma=1e-6_C=100.sav\", 891943206)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. Tests sur terrain"
      ],
      "metadata": {
        "id": "WfhVpCi7M31a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importer le modèle \n",
        "import pickle \n",
        "model=pickle.load(open('/content/drive/MyDrive/modèle_RBF_Gamma=1e-6_C=100.sav',\n",
        "                       'rb'))"
      ],
      "metadata": {
        "id": "I1caEDL5AD6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selecteur=SelectPercentile(kruskal,percentile=60)\n",
        "selecteur.fit(df1,y_train)\n",
        "scaler=StandardScaler()\n",
        "selecteur.fit(df1,y_train)\n",
        "x_train=df1.T[selecteur.get_support()].T\n",
        "x_train=scaler.fit_transform(x_train)"
      ],
      "metadata": {
        "id": "WU6_b3Dn53BS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_images=20\n",
        "path='/content/drive/MyDrive/tests'\n",
        "batch_size=1\n",
        "target_size=(224,224)\n",
        "class_names={0:'bacterial spot',1:'early blight',\n",
        "             2:'late blight',3:'leaf mold',\n",
        "             4:'septoria leaf spot',5:'spider mites',\n",
        "             6:'target spot',7:'yellow leaf curl virus',\n",
        "             8:'mosaic virus',9:'healthy'}\n",
        "n_variables=vgg19.output_shape[1]*vgg19.output_shape[2]*vgg19.output_shape[3] "
      ],
      "metadata": {
        "id": "VcGpOGw04CGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction():\n",
        "    images_dir = os.path.join(path)\n",
        "    datagenerator = ImageDataGenerator()\n",
        "    generator=datagenerator.flow_from_directory(images_dir,\n",
        "   target_size=target_size,batch_size=batch_size,shuffle=False,class_mode=None)\n",
        "    scaler=StandardScaler()\n",
        "    x_train=df1.T[selecteur.get_support()].T\n",
        "    x_train=scaler.fit_transform(x_train)\n",
        "    i=0\n",
        "    filenames=[]\n",
        "    images=[]\n",
        "    features = np.empty(shape=(n_images,vgg19.output_shape[1],\n",
        "                               vgg19.output_shape[2],vgg19.output_shape[3]))\n",
        "    for images_batch in tqdm(generator):\n",
        "      images.append(images_batch[0].astype('uint'))\n",
        "      preprocessed_batch=preprocess_input(images_batch)\n",
        "      features[i*batch_size:(i+1)*batch_size]= vgg19.predict(preprocessed_batch)\n",
        "      idx = generator.batch_index* generator.batch_size\n",
        "      filenames.append(str(generator.filenames[idx : idx + generator.batch_size][0]).replace('images/','').replace('.jpg',''))\n",
        "      i+= 1\n",
        "      if i==n_images:\n",
        "          break\n",
        "    features=np.reshape(features,(n_images,n_variables))\n",
        "    df=pd.DataFrame(features, columns = ['feature {}'.format(i) for i in range(n_variables)])\n",
        "    x=df.T[selecteur.get_support()].T\n",
        "    x=scaler.transform(x)\n",
        "    prediction=model.predict(x)\n",
        "    predicted_classes=[class_names[x] for x in prediction]\n",
        "    return(images,filenames,predicted_classes)"
      ],
      "metadata": {
        "id": "WTKUoeObBEc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,filenames,predicted_classes=prediction()\n",
        "def Show(i):\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(images[i])\n",
        "  plt.title('predicted :'+predicted_classes[i]+'\\n'+'True :'+filenames[i])\n",
        "  plt.axis('off')"
      ],
      "metadata": {
        "id": "9OGTpotPnL2i"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}